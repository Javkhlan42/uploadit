# Yellow Books AI Assistant - Implementation Guide

## üéØ –¢”©—Å–ª–∏–π–Ω –µ—Ä”©–Ω—Ö–∏–π –∑–æ—Ä–∏–ª–≥–æ

Yellow Books –≤—ç–± –∞–ø–ø-–¥ AI Assistant (semantic search + RAG) —Ñ—É–Ω–∫—Ü –Ω—ç–º—Å—ç–Ω. –≠–Ω—ç —Å–∏—Å—Ç–µ–º –Ω—å:
- –ú–æ–Ω–≥–æ–ª —Ö—ç–ª–Ω–∏–π –∞—Å—É—É–ª—Ç—ã–≥ –æ–π–ª–≥–æ—Ö
- Embedding –∞—à–∏–≥–ª–∞–Ω semantic similarity —Ö–∞–π–ª—Ç —Ö–∏–π—Ö
- LLM-—ç—ç—Ä –±–∞–π–≥–∞–ª–∏–π–Ω —Ö—ç–ª—ç—ç—Ä —Ö–∞—Ä–∏—É “Ø“Ø—Å–≥—ç—Ö

## üèóÔ∏è –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–π–Ω —Å—Ç–µ–∫

- **Frontend**: Next.js 15 (`/assistant` route)
- **Backend**: Express.js (NestJS –±—É—Å, —ç–Ω–≥–∏–π–Ω Express)
- **Database**: PostgreSQL + Prisma
- **Vector storage**: Prisma JSON field (pgvector –±–∏—à)
- **Cache**: Redis (optional, graceful fallback)
- **AI Provider**: Google Gemini API
  - `embedding-001` - Embeddings
  - `gemini-pro` - Chat Completion

## üìä Database Schema

```prisma
model YellowBook {
  // ... existing fields
  embedding    Json?    @db.JsonB  // ‚Üê NEW: Vector storage as JSON
}
```

## üöÄ Setup Instructions

### 1. Install Dependencies

```bash
npm install
```

Dependencies added:
- `@google/generative-ai` - Gemini SDK
- `ioredis` - Redis client (already installed)

### 2. Environment Variables

Add to your `.env`:

```env
# Gemini API Key
GEMINI_API_KEY=AIzaSyAJHQ7jY4Um0TfiOT86cgsf049fH_RCUb4

# Redis (optional - system works without it)
REDIS_URL=redis://localhost:6379

# API URL for frontend
NEXT_PUBLIC_API_URL=http://localhost:3333
```

### 3. Database Migration

```bash
# Generate migration for embedding field
npx prisma migrate dev --name add_embedding_to_yellowbook

# Apply migration
npx prisma generate
```

### 4. Generate Embeddings

Run the offline script to generate embeddings for all businesses:

```bash
npx ts-node tools/embed-businesses.ts
```

This script:
- Fetches all businesses without embeddings
- Generates text: `name + category + city + state + description`
- Calls Gemini API to create embedding vectors
- Saves to database
- Rate limited: 1 request/second

**Expected output:**
```
üöÄ Starting embedding generation...
üìä Found 150 businesses to process

Processing [1/150]: Restaurant Name
‚úÖ Success (768 dimensions)

Processing [2/150]: Hotel Name
‚úÖ Success (768 dimensions)
...
```

### 5. Start Services

```bash
# Terminal 1: Start Redis (optional)
redis-server

# Terminal 2: Start API
npm run start:api

# Terminal 3: Start Web
npm run start:web
```

### 6. Access AI Assistant

Open browser: `http://localhost:4200/assistant`

## üìÅ File Structure

```
yellow-book/
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îî‚îÄ‚îÄ embed-businesses.ts          # Offline embedding generator
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ main.ts               # Added AI endpoint
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ ai.service.ts     # Gemini integration
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ cache.service.ts  # Redis caching
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ similarity.ts     # Cosine similarity
‚îÇ   ‚îî‚îÄ‚îÄ web/
‚îÇ       ‚îî‚îÄ‚îÄ src/
‚îÇ           ‚îî‚îÄ‚îÄ app/
‚îÇ               ‚îî‚îÄ‚îÄ assistant/
‚îÇ                   ‚îî‚îÄ‚îÄ page.tsx      # AI Assistant UI
‚îî‚îÄ‚îÄ prisma/
    ‚îî‚îÄ‚îÄ schema.prisma                 # Updated with embedding field
```

## üîÑ AI Search Flow

```
User Question (Mongolian)
    ‚Üì
1. Check Redis Cache (key: ai:q:hash(question+city))
    ‚Üì (cache miss)
2. Generate Question Embedding (Gemini embedding-001)
    ‚Üì
3. Fetch Businesses from DB (with city/category filters)
    ‚Üì
4. Calculate Cosine Similarity for each business
    ‚Üì
5. Sort by similarity, take top 5
    ‚Üì
6. Generate AI Answer using RAG (Gemini gemini-pro)
    ‚Üì
7. Cache result (30 min TTL)
    ‚Üì
8. Return { answer, businesses, metadata }
```

## üéØ API Endpoint

### POST `/api/ai/yellow-books/search`

**Request:**
```json
{
  "question": "–¢”©–≤ –¥“Ø“Ø—Ä—ç–≥—Ç —Å–∞–π–Ω —Ä–µ—Å—Ç–æ—Ä–∞–Ω –±–∞–π–Ω–∞ —É—É?",
  "city": "–°“Ø—Ö–±–∞–∞—Ç–∞—Ä",        // optional
  "category": "–†–µ—Å—Ç–æ—Ä–∞–Ω",      // optional
  "limit": 5                    // optional, default 5
}
```

**Response:**
```json
{
  "answer": "–¢–∞–Ω—Ç–∞–π —Å–∞–Ω–∞–ª –±–æ–ª–≥–æ—Ö —Ö—ç–¥ —Ö—ç–¥—ç–Ω —Ä–µ—Å—Ç–æ—Ä–∞–Ω...",
  "businesses": [
    {
      "id": "uuid",
      "businessName": "Restaurant XYZ",
      "category": "–†–µ—Å—Ç–æ—Ä–∞–Ω",
      "city": "–°“Ø—Ö–±–∞–∞—Ç–∞—Ä",
      "state": "–£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä",
      "address": "...",
      "phoneNumber": "...",
      "description": "...",
      "website": "...",
      "similarity": 0.87
    }
  ],
  "metadata": {
    "totalFound": 5,
    "filtered": {
      "city": "–°“Ø—Ö–±–∞–∞—Ç–∞—Ä",
      "category": null
    },
    "model": "gemini-pro"
  },
  "fromCache": false
}
```

## ü§ñ RAG Prompt Design

```typescript
const prompt = `–¢–∞ Yellow Books-—ã–Ω —Ç—É—Å–ª–∞—Ö –±”©–≥”©”©–¥ –£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä —Ö–æ—Ç—ã–Ω –±–∏–∑–Ω–µ—Å“Ø“Ø–¥–∏–π–≥ —Å–∞–Ω–∞–ª –±–æ–ª–≥–æ–¥–æ–≥.

**–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –∞—Å—É—É–ª—Ç:**
${question}

**–ö–æ–Ω—Ç–µ–∫—Å—Ç (–ó”©–≤—Ö”©–Ω —ç–¥–≥—ç—ç—Ä ”©–≥”©–≥–¥”©–ª –¥—ç—ç—Ä —Ç—É–ª–≥—É—É—Ä–ª–∞–Ω —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É):**
\`\`\`json
${businessesJson}
\`\`\`

**–î“Ø—Ä—ç–º:**
1. –ó”©–≤—Ö”©–Ω –¥—ç—ç—Ä—Ö JSON ”©–≥”©–≥–¥”©–ª –¥—ç—ç—Ä “Ø–Ω–¥—ç—Å–ª—ç–Ω —Ö–∞—Ä–∏—É–ª–Ω–∞
2. 3-5 –±–∏–∑–Ω–µ—Å —Å–∞–Ω–∞–ª –±–æ–ª–≥–æ–Ω–æ (—Ö–∞–º–≥–∏–π–Ω —Ç–æ—Ö–∏—Ä–æ–º–∂—Ç–æ–π–≥ —ç—Ö—ç–ª–∂)
3. –ë–∏–∑–Ω–µ—Å–∏–π–Ω –Ω—ç—Ä –±–æ–ª–æ–Ω –±–∞–π—Ä—à–ª—ã–≥ (–¥“Ø“Ø—Ä—ç–≥) –∑–∞–∞–≤–∞–ª –¥—É—Ä–¥–∞–Ω–∞
4. –ù–∞–π—Ä—Å–∞–≥, —ç–Ω–≥–∏–π–Ω –º–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä —Ö–∞—Ä–∏—É–ª–Ω–∞
5. –•—ç—Ä—ç–≤ —Ç–æ—Ö–∏—Ä–æ—Ö –±–∏–∑–Ω–µ—Å –æ–ª–¥–æ—Ö–≥“Ø–π –±–æ–ª "–£—É—á–ª–∞–∞—Ä–∞–π, —Ç–∞–Ω—ã —Ö“Ø—Å—Å—ç–Ω –∫—Ä–∏—Ç–µ—Ä—Ç —Ç–æ—Ö–∏—Ä–æ—Ö –≥–∞–∑–∞—Ä –æ–ª–¥—Å–æ–Ω–≥“Ø–π" –≥—ç–∂ —Ö–∞—Ä–∏—É–ª–Ω–∞
6. –¢–∞–∞–º–∞–≥–ª–∞–∂, –∑–æ—Ö–∏–æ–∂ –±“Ø“Ø —Ö–∞—Ä–∏—É–ª - –∑”©–≤—Ö”©–Ω ”©–≥”©–≥–¥—Å”©–Ω –º—ç–¥—ç—ç–ª—ç–ª –∞—à–∏–≥–ª–∞

**–•–∞—Ä–∏—É–ª—Ç (–ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä):**`;
```

## üßÆ Cosine Similarity Algorithm

```typescript
function cosineSimilarity(vecA: number[], vecB: number[]): number {
  let dotProduct = 0;
  let normA = 0;
  let normB = 0;
  
  for (let i = 0; i < vecA.length; i++) {
    dotProduct += vecA[i] * vecB[i];
    normA += vecA[i] * vecA[i];
    normB += vecB[i] * vecB[i];
  }
  
  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}
```

Result: 0 to 1 (higher = more similar)

## üíæ Caching Strategy

- **Key format**: `ai:q:${hash(question + city + category)}`
- **TTL**: 30 minutes
- **Graceful degradation**: Works without Redis
- **Cache invalidation**: Manual or TTL expiry

## üé® UI Features

### Assistant Page (`/assistant`)

1. **Search Form**
   - Main question input (textarea)
   - Optional city filter
   - Optional category filter
   - Submit button with loading state

2. **Example Questions**
   - Quick-fill buttons with Mongolian examples

3. **AI Response Display**
   - Formatted AI answer
   - Model indicator (gemini-pro)
   - Cache status indicator

4. **Business Cards**
   - Top 5 businesses
   - Similarity score (percentage)
   - Full contact details
   - Clickable phone/website

5. **Responsive Design**
   - Mobile-friendly
   - Tailwind CSS
   - Gradient accents

## üîß Testing

### Test Embedding Generation

```bash
# Test with one business
npx ts-node -e "
import { PrismaClient } from '@prisma/client';
const prisma = new PrismaClient();
prisma.yellowBook.findFirst({ where: { embedding: { not: null } } })
  .then(b => console.log('Embedding dimensions:', (b.embedding as any).length));
"
```

### Test AI Search

```bash
curl -X POST http://localhost:3333/api/ai/yellow-books/search \
  -H "Content-Type: application/json" \
  -d '{
    "question": "–°“Ø—Ö–±–∞–∞—Ç–∞—Ä –¥“Ø“Ø—Ä—ç–≥—Ç —Å–∞–π–Ω —Ä–µ—Å—Ç–æ—Ä–∞–Ω –±–∞–π–Ω–∞ —É—É?",
    "limit": 3
  }'
```

### Test Cache

1. Make request ‚Üí should see `"fromCache": false`
2. Same request again ‚Üí should see `"fromCache": true`

## üìä Performance Considerations

- **Embedding generation**: ~1 second per business (rate limited)
- **Search query**: ~2-3 seconds (including LLM call)
- **Cached query**: ~50-100ms
- **Database**: Uses JSON field (consider pgvector for production)

## üöß Limitations & Future Improvements

### Current Limitations
1. JSON storage (not optimized for large scale)
2. No pgvector index
3. Single API key (no rate limit handling)
4. No user authentication on assistant page

### Future Improvements
1. **pgvector**: Native vector similarity in PostgreSQL
2. **Batch embedding**: Parallel processing
3. **Advanced filtering**: Price, rating, hours
4. **Conversation history**: Multi-turn dialogue
5. **Analytics**: Track popular questions
6. **A/B testing**: Different prompts/models

## üìù Code Principles

- ‚úÖ Simple, readable, demo-quality
- ‚úÖ Graceful error handling
- ‚úÖ Works without Redis
- ‚úÖ Mongolian language support
- ‚úÖ RAG pattern with strict prompt
- ‚úÖ No hallucination (only DB data)
- ‚úÖ Cache for performance

## üéì Educational Value

This implementation demonstrates:
- **Semantic Search**: Understanding meaning, not just keywords
- **RAG Pattern**: Grounding LLM with real data
- **Embedding**: Vector representations of text
- **Cosine Similarity**: Measuring semantic similarity
- **Caching**: Performance optimization
- **Full-stack AI**: Frontend ‚Üí Backend ‚Üí AI ‚Üí Database

## üÜò Troubleshooting

### Embedding generation fails
```
Error: quota exceeded
```
‚Üí Wait and retry, or use different API key

### Redis connection error
```
Redis error: ECONNREFUSED
```
‚Üí OK! System works without Redis

### No businesses found
```
"businesses": []
```
‚Üí Run embedding script first: `npx ts-node tools/embed-businesses.ts`

### CORS error on frontend
```
Access-Control-Allow-Origin
```
‚Üí Check `NEXT_PUBLIC_API_URL` in `.env`

## üìö Resources

- [Gemini API Docs](https://ai.google.dev/docs)
- [Embeddings Guide](https://ai.google.dev/docs/embeddings_guide)
- [RAG Pattern](https://arxiv.org/abs/2005.11401)
- [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)

---

**Status**: ‚úÖ Lab Complete
**Date**: December 19, 2025
**Version**: 1.0.0
